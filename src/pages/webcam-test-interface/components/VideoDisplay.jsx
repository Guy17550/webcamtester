import React, { useEffect, useRef, useState } from "react";

import { analyzeGesture } from "../gesture/gestureEngine";

// ðŸ”¹ sentence layer (SINGLE SOURCE OF TRUTH)
import {
  acceptWord,
  getSentenceState,
  resetSentence,
  undoLastWord,
  pauseSentence,
  resumeSentence,
  confirmSentence,
} from "../gesture/sentenceEngine";

const COOLDOWN_MS = 400;

const VideoDisplay = ({ videoRef, isActive }) => {
  const canvasRef = useRef(null);
  const handsRef = useRef(null);
  const rafRef = useRef(null);

  const prevLandmarksRef = useRef(null);
  const cooldownUntilRef = useRef(0);

  // UI state
  const [detectedWord, setDetectedWord] = useState("");
  const [gestureStatus, setGestureStatus] = useState("à¸à¸³à¸¥à¸±à¸‡à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š...");
  const [sentenceText, setSentenceText] = useState("");
  const [isPaused, setIsPaused] = useState(false);
  const [isConfirmed, setIsConfirmed] = useState(false);
  const [debugInfo, setDebugInfo] = useState(null);

  /* =========================
     ðŸ”Š TEXT TO SPEECH
  ========================= */
  const speakSentence = () => {
    if (!sentenceText) return;

    const utterance = new SpeechSynthesisUtterance(sentenceText);
    utterance.lang = "th-TH";
    utterance.rate = 0.9;
    utterance.pitch = 1.0;

    window.speechSynthesis.cancel();
    window.speechSynthesis.speak(utterance);
  };

  /* =========================
     MAIN EFFECT
  ========================= */
  useEffect(() => {
    if (!isActive || !videoRef?.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d");

    const syncCanvas = () => {
      if (!video.videoWidth) return;
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    };

    const drawHand = (hand) => {
      ctx.fillStyle = "#00ff00";
      ctx.strokeStyle = "#00ff00";
      ctx.lineWidth = 2;

      hand.forEach((p) => {
        ctx.beginPath();
        ctx.arc(
          p.x * canvas.width,
          p.y * canvas.height,
          4,
          0,
          Math.PI * 2
        );
        ctx.fill();
      });
    };

    const onResults = (results) => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (results?.multiHandLandmarks?.[0]) {
        drawHand(results.multiHandLandmarks[0]);
      }

      const now = Date.now();
      if (now < cooldownUntilRef.current) return;

      const result = analyzeGesture(results, prevLandmarksRef.current);
      prevLandmarksRef.current = result?.previousLandmarks;
      setDebugInfo(result?.debug);

      const state = result?.gestureState;

      /* ---------- STATE UI ---------- */
      if (state === "idle") {
        setGestureStatus("à¸à¸³à¸¥à¸±à¸‡à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸š...");
        setDetectedWord("");
      }

      else if (state === "tracking") {
        setGestureStatus("à¸à¸³à¸¥à¸±à¸‡à¸•à¸´à¸”à¸•à¸²à¸¡...");
      }

      else if (state === "confirmed") {
        setGestureStatus("à¸¢à¸·à¸™à¸¢à¸±à¸™à¹à¸¥à¹‰à¸§");

        if (result?.detectedWord && !isPaused && !isConfirmed) {
          acceptWord(result.detectedWord);

          // âœ… à¸­à¹ˆà¸²à¸™ sentence à¸ˆà¸²à¸ sentenceEngine à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
          const sentenceState = getSentenceState();
          setSentenceText(sentenceState.formatted);

          setDetectedWord(result.detectedWord);
          cooldownUntilRef.current = Date.now() + COOLDOWN_MS;
        }
      }

      else if (state === "ended") {
        setGestureStatus("à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™");
      }

      if (result?.detectedWord === null && state === "idle") {
        setDetectedWord("");
      }
    };

    const hands = new window.Hands({
      locateFile: (f) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}`,
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.6,
    });

    hands.onResults(onResults);
    handsRef.current = hands;

    const loop = async () => {
      if (video.readyState >= 2) {
        syncCanvas();
        await hands.send({ image: video });
      }
      rafRef.current = requestAnimationFrame(loop);
    };

    loop();

    return () => {
      if (rafRef.current) cancelAnimationFrame(rafRef.current);
      if (handsRef.current) handsRef.current.close();
    };
  }, [isActive, videoRef, isPaused, isConfirmed]);

  /* =========================
     UI
  ========================= */
  return (
    <div>
      <div className="relative">
        <video
          ref={videoRef}
          autoPlay
          muted
          playsInline
          className="w-full"
        />
        <canvas
          ref={canvasRef}
          className="absolute top-0 left-0 w-full h-full"
          style={{ pointerEvents: "none" }}
        />
      </div>

      <div className="mt-3 text-sm">
        à¸ªà¸–à¸²à¸™à¸°: <b>{gestureStatus}</b>
      </div>

      <div className="text-4xl font-bold mt-4 text-green-600">
        {detectedWord || "â€”"}
      </div>

      <div className="text-xl mt-4">
        à¸›à¸£à¸°à¹‚à¸¢à¸„: <b>{sentenceText || "â€”"}</b>
      </div>

      {/* CONTROLS */}
      <div className="mt-4 flex gap-2 flex-wrap">
        <button
          className="px-4 py-2 bg-yellow-500 text-white rounded"
          onClick={() => {
            if (isPaused) {
              resumeSentence();
              setIsPaused(false);
            } else {
              pauseSentence();
              setIsPaused(true);
            }
          }}
        >
          {isPaused ? "Resume" : "Pause"}
        </button>

        <button
          className="px-4 py-2 bg-blue-500 text-white rounded"
          onClick={() => {
            undoLastWord();
            setSentenceText(getSentenceState().formatted);
          }}
        >
          Undo à¸„à¸³à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
        </button>

        <button
          className="px-4 py-2 bg-green-600 text-white rounded"
          onClick={() => {
            const result = confirmSentence();
            if (result.confirmed) {
              setIsConfirmed(true);
              alert("à¸¢à¸·à¸™à¸¢à¸±à¸™à¸›à¸£à¸°à¹‚à¸¢à¸„: " + result.formatted);
            }
          }}
        >
          à¸¢à¸·à¸™à¸¢à¸±à¸™à¸›à¸£à¸°à¹‚à¸¢à¸„
        </button>

        <button
          className="px-4 py-2 bg-red-500 text-white rounded"
          onClick={() => {
            resetSentence();
            setSentenceText("");
            setIsPaused(false);
            setIsConfirmed(false);
          }}
        >
          à¸¥à¸šà¸„à¸³à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
        </button>

        <button
          className="px-4 py-2 bg-purple-600 text-white rounded"
          onClick={speakSentence}
          disabled={!sentenceText}
        >
          ðŸ”Š à¸­à¹ˆà¸²à¸™à¸›à¸£à¸°à¹‚à¸¢à¸„
        </button>
      </div>

      {debugInfo && (
        <pre className="mt-3 text-xs bg-gray-100 p-2 rounded">
          {JSON.stringify(debugInfo, null, 2)}
        </pre>
      )}
    </div>
  );
};

export default VideoDisplay;